/** Size */
interface Size {
    /** Width */
    width: number;
    /** Height */
    height: number;
}
/** Image input types (supported) */
declare type ImageInput = ImageData | ImageBytes | HTMLCanvasElement;
/** Image bytes buffer */
interface ImageBytes {
    /** Pixel buffer */
    data: Uint8Array;
    /** Width in pixels */
    width: number;
    /** Height in pixels */
    height: number;
}

declare type Args<F> = [F] extends [(...args: infer U) => any] ? U : [F] extends [void] ? [] : [F];
/**
 * EventEmitter class
 *
 * These objects expose an on() function that allows one or more
 * functions to be attached to named events emitted by the object.
 * When the EventEmitter object emits an event, all of the functions
 * attached to that specific event are called synchronously. Any
 * values returned by the called listeners are ignored and discarded.
 *
 * @typeParam Events - Events emitted by EventEmitter
 */
interface EventEmitterTI<Events> {
    /**
     * Adds the listener function to the event
     *
     * @param event - The name of the event
     * @param listener - The callback function
     * @returns This EventEmitter
     */
    on<E extends keyof Events>(event: E, listener: Events[E]): this;
    /**
     * Adds a one-time listener function for the event
     *
     * @param event - The name of the event
     * @param listener - The callback function
     * @returns This EventEmitter
     */
    once<E extends keyof Events>(event: E, listener: Events[E]): this;
    /**
     * Removes the listener from the listener array for the event
     *
     * @param event - The name of the event
     * @param listener - The callback function
     * @returns This EventEmitter
     */
    off<E extends keyof Events>(event: E, listener: Events[E]): this;
    /**
     * Adds the listener function to the end of the listeners array
     *
     * @param event - The name of the event
     * @param listener - The callback function
     * @returns This EventEmitter
     */
    addListener<E extends keyof Events>(event: E, listener: Events[E]): this;
    /**
     * Adds the listener function to the beginning of the listeners array
     *
     * @param event - The name of the event
     * @param listener - The callback function
     * @returns This EventEmitter
     */
    prependListener<E extends keyof Events>(event: E, listener: Events[E]): this;
    /**
     * Adds a one-time listener function to the beginning of the listeners array
     *
     * @param event - The name of the event
     * @param listener - The callback function
     */
    prependOnceListener<E extends keyof Events>(event: E, listener: Events[E]): this;
    /**
     * Removes the specified listener from the listener array
     *
     * @param event - The name of the event
     * @param listener - The callback function
     * @returns This EventEmitter
     */
    removeListener<E extends keyof Events>(event: E, listener: Events[E]): this;
    /**
     * Removes all listeners, or those of the specified event
     *
     * @param event - The name of the event
     * @returns This EventEmitter
     */
    removeAllListeners<E extends keyof Events>(event?: E): this;
    /**
     * Synchronously calls each of the listeners registered for the event
     *
     * @param event - The name of the event
     * @param args - Arguments passed to the listeners
     * @returns True if the event had listeners, False otherwise
     */
    emit<E extends keyof Events>(event: E, ...args: Args<Events[E]>): boolean;
    /**
     * The number of listeners listening to the event
     *
     * @param event - The name of the event
     * @returns Number of listeners
     */
    listenerCount<E extends keyof Events>(event: E): number;
    /**
     * Copy of the array of listeners for the event
     *
     * @param event - The name of the event
     * @returns Copy of the listeners array
     */
    listeners<E extends keyof Events>(event: E): Function[];
    /**
     * Copy of the array of listeners for the event including wrappers
     *
     * @param event The name of the event
     * @returns Copy of the listeners array
     */
    rawListeners<E extends keyof Events>(event: E): Function[];
    /**
     * Sets maximum number of listeners per event
     *
     * @param n - Maximum number of listeners
     * @returns This EventEmitter
     */
    setMaxListeners(n: number): this;
    /**
     * Maximum number of listeners per event
     * @returns Maximum number of listeners per event
     */
    getMaxListeners(): number;
    /**
     * List of emitter's events
     * @returns List of emitter's events
     */
    eventNames(): (keyof Events | string | symbol)[];
}
declare const EventEmitterT_base: new <Events_1>() => EventEmitterTI<Events_1>;
/**
 * EventEmitter generic class
 *
 * These objects expose an on() function that allows one or more
 * functions to be attached to named events emitted by the object.
 * When the EventEmitter object emits an event, all of the functions
 * attached to that specific event are called synchronously. Any
 * values returned by the called listeners are ignored and discarded.
 *
 * @typeParam Events - Events emitted by EventEmitter
 */
declare class EventEmitterT<Events> extends EventEmitterT_base<Events> {
}

/**
 * Image buffer
 *
 * Helper class grabbing images into internal storage.
 * Used by [[VideoSource]] to grab video streams and
 * [[Engine]] to resize images for faster processing.
 * Image can be accessed by canvas or read as pixels.
 */
declare class ImageBuffer {
    /** Size of video */
    size: Size;
    /** Canvas to capture frames */
    canvas: HTMLCanvasElement;
    /** Context to capture frames */
    protected context: CanvasRenderingContext2D | null;
    /**
     * Constructor
     *
     * @param name - Optional name of canvas
     */
    constructor(name?: string);
    /**
     * Grab frame
     *
     * Grabs frame from video element or canvas into internal canvas.
     * Automatically rescales an image if resolutions are different.
     *
     * @param video - Element to grab image from
     * @returns True if image is grabbed, False otherwise
     */
    capture(video: HTMLVideoElement | HTMLCanvasElement): boolean;
    /**
     * Get image buffer
     *
     * Returns data buffer of image currently grabbed into canvas.
     *
     * @returns Image data buffer on success, undefined otherwise
     */
    data(): ImageData | undefined;
    /** Set video size */
    setSize(size: Size): void;
    /** Fill canvas with color */
    fill(): void;
    /** Dispose video context object */
    dispose(): void;
}
/** Parameters of video capture */
interface VideoParams {
    /** Size requested from a camera */
    size?: Size;
    /** Request rear-facing camera if presented */
    rear?: boolean;
}
/** Setup parameters of video capture */
declare type VideoSourceParams = VideoParams | MediaStreamConstraints | MediaStream | string;
/** Events emitted by [[VideoCapture]] */
interface CaptureEvents {
    /** Video resize */
    resize: (size: Size) => void;
}
/**
 * Video source
 *
 * General class of video capture objects providing
 * functionality to grab images from various sources.
 * It implements basic interfaces like setup, start,
 * stop of the video capture, and grabbing of frames.
 * Internally utilizes [[ImageBuffer]] as storages.
 */
declare class VideoSource extends EventEmitterT<CaptureEvents> {
    /** Context of original stream */
    buffer: ImageBuffer;
    /** Timestamp of the last captured frame */
    captureTime: number;
    /** Timer to emulate timestamps */
    private timer?;
    /** Constructor */
    constructor();
    /**
     * Setup video source
     *
     * Sets up capture, overridden for particular video source.
     * Video source can be set up by simplified [[VideoParams]]
     * opening default front/rear camera with provided resolution,
     * custom MediaStreamConstraints providing the most flexible
     * way to setup video stream (e.g. set deviceId), or external
     * MediaStream allowing custom video sources (e.g. from file).
     * Default implementation sets video resolution according to
     * size in provided [[VideoParams]] or 1920x1080 as fallback.
     * It captures static image, canvas is filled by white color.
     *
     * @param params - Parameters of video capture
     * @returns Promise resolved to the status of setup when done
     * @virtual
     */
    setup(params?: VideoSourceParams): Promise<boolean>;
    /**
     * Dispose video source object
     *
     * @virtual
     */
    dispose(): void;
    /**
     * Start video capture
     *
     * Video capture can be started only after successful setup().
     *
     * @returns Promise resolved when capture is started
     * @virtual
     */
    start(): Promise<void>;
    /**
     * Pause video capture
     *
     * @virtual
     */
    pause(): void;
    /**
     * Reset video capture
     *
     * After reset() capture may be started again only after setup().
     *
     * @virtual
     */
    reset(): void;
    /**
     * Grab the next video frame
     *
     * VideoSource grabs static image permanently
     * stored in embedded [[ImageBuffer]] object.
     *
     * @returns True if next frame was available and grabbed
     * @virtual
     */
    capture(): boolean;
    /**
     * Resolution of the video stream
     *
     * @returns Resolution of the video stream
     */
    size(): Size;
    /**
     * Aspect ratio of the video stream
     *
     * @returns Aspect ratio of the video stream
     */
    ratio(): number;
    /**
     * Update callback on video resize
     *
     * @param size - New size of the video stream
     */
    protected updateSize(size: Size): void;
}

/** Basic processor parameters */
interface ProcParams {
    /**
     * The SDK access token. Mandatory parameter authenticating
     * your user account and providing access to the SDK on the
     * current url. You can create tokens for required urls on
     * your [account page](https://builder.geenee.ar/sdk). Token
     * must be provided to initialize [[Engine.init | Engine]].
     * [More](https://lab.geen.ee/engeenee-doc/#getting-started).
     */
    token: string;
    /**
     * Root path to computational modules (statically served wasms).
     * The SDK requires access to wasm modules provided within its
     * packages. By default, the root path is the current url "./".
     * Root can be set on [[Engine.init | Engine initialization]].
     */
    root?: string;
    /** Cache computational modules (experimental) */
    cache?: boolean;
}
/** Events emitted by [[Processor]] */
interface ProcessorEvents {
    /** Processor initialized */
    init: (status: boolean) => void;
    /** Processor reset */
    reset: () => void;
}
/**
 * Core generic processor
 *
 * Processor is a computational core of any application and the
 * most essential part of the [[Engine]] in an app's pipeline.
 * Results of processing are used by [[Renderer]] to update scene.
 * Every processor must define methods to initialize and release
 * instances required for image processing, and evaluation of
 * processing results on provided image (where all logic happens).
 * Processor is a generic abstract class defining common API.
 *
 * @typeParam ResultT - Type of processing results
 * @typeParam ParamsT - Type of processor parameters
 */
declare class Processor<ResultT extends {} = {}, ParamsT extends ProcParams = ProcParams> extends EventEmitterT<ProcessorEvents> {
    /** Processor parameters */
    protected params: Partial<ParamsT>;
    /** Resolution of input video */
    protected videoSize: Size;
    /** Aspect ratio of input video */
    protected videoRatio: number;
    /** Recommended maximum size of input */
    optimalSize: number;
    /** Camera aspect ratio */
    cameraRatio: number;
    /** Camera vertical angle in radians */
    cameraAngle: number;
    /**
     * Constructor
     *
     * @param params - Processor parameters
     */
    constructor();
    /**
     * Process the image
     *
     * Main method defining the logic of video processing.
     * Overridden by derived classes for particular application.
     *
     * @param input - Image
     * @param timestamp - Timestamp
     * @virtual
     */
    process(input: ImageInput, timestamp?: number): Promise<ResultT | undefined>;
    /**
     * Initialize processor
     *
     * Initializes all resources required for video processing.
     * Overridden by derived classes for particular application.
     *
     * @param params - Processor parameters
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @returns Status of initialization
     * @virtual
     */
    init(params: ParamsT, size?: Size, ratio?: number): Promise<boolean>;
    /**
     * Reset processor
     *
     * Resets all processing instances to the initial state.
     * Overridden by derived classes for particular processing.
     *
     * @virtual
     */
    reset(): void;
    /**
     * Dispose processor object
     *
     * Releases resources and instances allocated by processor.
     * Processor object cannot be used after calling dispose().
     * Overridden by derived classes for particular processing.
     *
     * @virtual
     */
    dispose(): void;
    /**
     * Set resolution of the input video
     *
     * Could be overridden to adjust processing pipeline.
     *
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @virtual
     */
    setupVideo(size: Size, ratio?: number): void;
}

/** Events emitted by [[Renderer]] */
interface RendererEvents {
    /** Renderer initialized */
    load: () => void;
    /** Scene updated, emitted on every iteration */
    render: () => void;
    /** Rendering canvas resized */
    resize: (size: Size, ratio: number) => void;
}
/**
 * Core generic renderer
 *
 * Renderer is the core visualization part of any application.
 * It's attached to the [[Engine]]. Results of processing and
 * captured frame are provided to renderer that updates scene,
 * visualization and application logic according to this data.
 * Basically, renders define two methods load() and update().
 * The first one is used to initialize all assets and prepare
 * the scene e.g. set up lightning, environment map. Engine
 * will call load() method during pipeline initialization.
 * The second one is used to update the scene using results
 * of video processing. This's where all the logic happens.
 * By extending [[Renderer.load]] and [[Renderer.update]] you
 * can add any custom logic, interactions, animations, effects
 * post-processing, gesture recognition, physics, etc. to app.
 * Renderer is a generic abstract class defining common API.
 *
 * @typeParam ResultT - Type of processing results
 */
declare class Renderer<ResultT> extends EventEmitterT<RendererEvents> {
    /** Loaded state */
    protected loaded: boolean;
    /** Resolution of input video */
    protected videoSize: Size;
    /** Aspect ratio of input video */
    protected videoRatio: number;
    /** Camera aspect ratio */
    protected cameraRatio: number;
    /** Camera vertical angle in radians */
    protected cameraAngle: number;
    /**
     * Constructor
     */
    constructor();
    /**
     * Initialize renderer
     *
     * Initializes renderer, all required assets, and the scene.
     * Overridden by derived classes for particular application.
     *
     * @returns Promise resolving when initialization is finished
     * @virtual
     */
    load(): Promise<void>;
    /**
     * Reset renderer
     *
     * Releases all resources and instances created in load().
     * Overridden by derived classes for particular application.
     *
     * @virtual
     */
    unload(): void;
    /**
     * Update the scene
     *
     * Main method defining the logic of the renderer.
     * Updates the scene according to provided results.
     * Overridden by derived classes for the application.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @virtual
     */
    update(result: ResultT, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Dispose renderer object
     *
     * @virtual
     */
    dispose(): void;
    /**
     * Set video parameters
     *
     * Could be overridden to adjust rendering pipeline.
     *
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @virtual
     */
    setupVideo(size: Size, ratio?: number): void;
    /**
     * Set camera parameters
     *
     * Some video processors statically define camera parameters
     * from just a video resolution. In this cases setupCamera()
     * is used to pass these static camera parameters to renderer.
     *
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @virtual
     */
    setupCamera(ratio: number, angle: number): void;
}

/** Parameters of Engine */
interface EngineParams {
    /** Maximum processing size (resizing). If not defined
     * engine uses image size preferred by processor. */
    max?: number;
    /** Preserve original resolution, default - true. */
    orig?: boolean;
}
/** Events emitted by [[Engine]] */
interface EngineEvents {
    /** Engine initialized */
    init: (status: boolean) => void;
    /** Engine set up */
    setup: (status: boolean) => void;
    /** Pipeline started */
    start: () => void;
    /** Pipeline stopped */
    pause: () => void;
}
/**
 * Core generic engine
 *
 * Engine is a core of any app and organizer of a pipeline.
 * It's responsible to interact with lower-level instances and
 * at the same time provide simple and user-friendly interface.
 * Engine combines together data (video) capturing, processing
 * and rendering. It is created for particular [[Processor]].
 * Processor's constructor is provided to the engine and former
 * initializes, sets up and controls state of processor during
 * life-circle of the application. Results of processing and
 * captured video are passed to a [[Renderer]] attached to the
 * Engine. Notable feature is fast rescaling of images before
 * processing down to the requested resolution in cases when
 * available camera output is bigger. Engine parameters have an
 * option to limit processed image size. Original video stream
 * can be preserved on request, this is useful when processing
 * cannot handle high resolution images but you still want to
 * render high quality video in your app. All core components:
 * Engine, Processor, and Renderer are generics parametrized by
 * type of processing results and optionally tuning parameters.
 *
 * @typeParam ProcessorT - Type of processor
 * @typeParam ResultT - Type of processing results
 * @typeParam ParamsT - Type of processor parameters
 */
declare class Engine<ResultT, ParamsT extends ProcParams, ProcessorT extends Processor<ResultT, ParamsT>> extends EventEmitterT<EngineEvents> {
    protected engineParams?: EngineParams | undefined;
    /** Processor utilized by the engine */
    protected processor: ProcessorT;
    /** Renderer attached to the engine */
    protected renderers: Renderer<ResultT>[];
    /** Video source instance */
    protected video: VideoSource;
    /** Ratio of video stream */
    protected videoRatio: number;
    /** Shallow copy of canvas with video for renderers */
    protected streamCanvas?: HTMLCanvasElement;
    /** Size of video for renderers */
    protected streamSize: Size;
    /** Shallow copy of canvas with video for processors */
    protected processCanvas?: HTMLCanvasElement;
    /** Size of video for processors */
    protected processSize: Size;
    /** Buffer to resize frames */
    protected resizeBuffer?: ImageBuffer;
    /** Original stream is resized */
    protected resizeEnabled: boolean;
    /** State of the pipeline */
    private loopState;
    /** Id of current frame */
    private loopId?;
    /**
     * Constructor
     *
     * @param Processor - Processor class or its constructor
     * @param engineParams - Parameters of the engine
     * @param Source - Video source class or its constructor
     * @typeParam ProcessorT - Type of processor
     * @typeParam ResultT - Type of processing results
     * @typeParam ParamsT - Type of processor parameters
     */
    constructor(Processor: new () => ProcessorT, engineParams?: EngineParams | undefined, Source?: new () => VideoSource);
    /**
     * Initialize engine. Sets up processor.
     *
     * The SDK [[ProcParams.token | access token]] is the
     * required parameter that authenticates the user and
     * enables the SDK on the current url. By default, path
     * to required wasm modules provided with SDK packages
     * is the current url. You can change the root path to
     * wasms passing [[ProcParams.root | root parameter]].
     *
     * @param - Parameters of the processor
     * @returns Status of initialization
     */
    init: (procParams: ParamsT) => Promise<boolean>;
    /**
     * Setup engine. Initializes video capture.
     *
     * Video capture can be set up by simplified [[VideoParams]]
     * opening default front/rear camera with provided resolution,
     * custom MediaStreamConstraints providing the most flexible
     * way to setup video stream (e.g. set deviceId), or external
     * MediaStream allowing custom video sources (e.g. from file).
     *
     * @param videoParams - Parameters of video capture
     * @returns Status of initialization
     */
    setup: (videoParams?: VideoSourceParams) => Promise<boolean>;
    /**
     * Start pipeline.
     *
     * Pipeline can be started only after successful init and setup.
     */
    start: () => Promise<void>;
    /**
     * Pause pipeline.
     *
     * Nothing happens if pipeline is not started yet.
     */
    pause: () => void;
    /**
     * Reset pipeline
     *
     * Stops pipeline, resets video capture and processor.
     * After reset one needs to reinitialize video capture
     * calling setup() before pipeline can be started again.
     */
    reset: () => void;
    /**
     * Attach Renderer to the engine
     *
     * @param renderer - Object to be attached
     */
    addRenderer(renderer: Renderer<ResultT>): Promise<void>;
    /**
     * Remove attached Renderer
     *
     * @param renderer - Renderer to be removed
     */
    removeRenderer(renderer: Renderer<ResultT>): void;
    /** Iterate */
    protected iterate: () => Promise<void>;
    /** Enqueue the next iteration */
    protected enqueue(): void;
    /** Setup processor */
    protected setupProcessor(procParams: ParamsT): Promise<boolean>;
    /** Setup video capture */
    protected setupVideo(videoParams?: VideoSourceParams): Promise<boolean>;
    /** Setup video size */
    protected setupSize(size: Size): Promise<void>;
    /**
     * Callback called when video resolution is changed
     *
     * @param size - Size of the video
     */
    protected resizeVideo(size: Size): void;
}

/**
 * Generic asynchronous engine
 *
 * AsyncEngine is extension of basic [[Engine]] that does
 * processing in the background. Its pipeline provides for
 * better performance and more stable frames per second. By
 * using async engine you can achieve smoother and faster
 * experience. AsyncEngine and Engine are compatible, you
 * can use any of them without additional code adjustments.
 *
 * @typeParam ProcessorT - Type of processor
 * @typeParam ResultT - Type of processing results
 * @typeParam ParamsT - Type of processor parameters
 */
declare class AsyncEngine<ResultT, ParamsT extends ProcParams, ProcessorT extends Processor<ResultT, ParamsT>> extends Engine<ResultT, ParamsT, ProcessorT> {
    /** Promise with result of async processing */
    private result?;
    /** Iterate
     *
     * Overridden for asynchronous processing.
    */
    protected iterate: () => Promise<void>;
}

/**
 * Video capture
 *
 * VideoCapture object provides means to grab images from a source.
 * It implements all required functionality including video device
 * initialization, setup, start/stop of capture and frame grabbing.
 * Internally VideoCapture utilizes [[ImageBuffer]] as a storages.
 */
declare class VideoCapture extends VideoSource {
    /** Video element */
    protected videoRef: HTMLVideoElement;
    /** Time shift for video loop */
    private timeShift;
    /** Constructor */
    constructor();
    /**
     * Setup video capture
     *
     * Sets up video device, streams and contexts with canvases.
     * Video capture can be set up by simplified [[VideoParams]]
     * opening default front/rear camera with provided resolution,
     * custom MediaStreamConstraints providing the most flexible
     * way to select the video stream (for example set deviceId),
     * external MediaStream allowing use of custom video sources,
     * or string defining a media file as source of video stream.
     *
     * @param params - Parameters of video capture
     * @returns Promise resolved to the status of setup when finished
     */
    setup(params?: VideoSourceParams): Promise<boolean>;
    /**
     * Dispose video capture object
     *
     * @override
     */
    dispose(): void;
    /**
     * Start video capture
     *
     * Video capture can be started only after successful setup().
     *
     * @returns Promise resolved when capture is started
     */
    start(): Promise<void>;
    /**
     * Pause video capture
     *
     * @override
     */
    pause(): void;
    /**
     * Reset video capture
     *
     * After reset() capture may be started again only after setup().
     *
     * @override
     */
    reset(): void;
    /**
     * Grab the next video frame
     *
     * VideoCapture grabs the next image from video source
     * (camera) and stores it in embedded [[ImageBuffer]].
     *
     * @returns True if next frame was available and grabbed
     * @override
     */
    capture(): boolean;
}

/** Events emitted by [[ResponsiveCanvas]] */
interface CanvasEvents {
    /** Resize event */
    resize: () => void;
}
/**
 * Responsive canvas
 *
 * Responsive canvas is useful helper for applications
 * doing rendering. It creates canvas layers within any
 * html element. Layers preserve aspect ratio according
 * to fitting mode. Ratio of canvas usually follows the
 * ratio of the input video. In "crop" mode canvases are
 * cropped to have the same aspect ratio as the container
 * and scaled to fill the whole area. This is default
 * mode preferred in most cases. In "fit mode" canvases
 * are scaled down to fit into the container and leaving
 * margins to stay in the center. ResponsiveCanvas tracks
 * size changes of the container and updates canvas sizes.
 */
declare class ResponsiveCanvas extends EventEmitterT<CanvasEvents> {
    protected container: HTMLElement;
    protected mode: "fit" | "crop";
    protected layerCount: number;
    protected mirror: boolean;
    protected aspectRatio: number;
    /** Canvas layers */
    layers: HTMLCanvasElement[];
    /** Resize observer */
    protected observer?: ResizeObserver;
    /**
     * Constructor
     *
     * @param container - Container of responsive canvas
     * @param mode - Fitting mode
     * @param layerCount - Number of canvas layers
     * @param mirror - Mirror the output
     * @param aspectRatio - Target aspect ratio
     */
    constructor(container: HTMLElement, mode?: "fit" | "crop", layerCount?: number, mirror?: boolean, aspectRatio?: number);
    /**
     * Set aspect ratio
     *
     * Responsive canvas will preserve provided aspect ratio and
     * resize itself within container according to fitting mode.
     *
     * @param ratio - Aspect ratio
     */
    setAspectRatio: (ratio: number) => void;
    /**
     * Set mirror mode
     *
     * ResponsiveCanvas mirrors the output layers.
     *
     * @param ratio - Mirror the output
     */
    setMirror: (mirror: boolean) => void;
    /**
     * Update canvas sizes to preserve aspect ratio
     *
     * Updates relative sizes of canvas within container to
     * preserve fixed aspect ratio according to fitting mode.
     * Called when container is resized (by resize observer).
     *
     * @param containerRatio - Aspect ratio of the container
     */
    protected updateSizes: (containerRatio: number) => void;
    /**
     * Resize event callback
     *
     * Callback attached to resize observer to handle size updates.
     * Basically, it calls updateSizes() to adjust canvas sizes.
     *
     * @param entries - Elements being resized
     */
    protected handleResize: (entries: ResizeObserverEntry[]) => void;
}

/** Parameters of [[CanvasRenderer]] */
interface CanvasParams {
    /** Container of responsive canvas */
    container: HTMLElement;
    /** Fitting mode */
    mode?: "fit" | "crop";
    /** Number of canvas layers */
    layerCount?: number;
    /** Mirror the output */
    mirror?: boolean;
    /** Target aspect ratio */
    aspectRatio?: number;
}
/**
 * Generic renderer using [[ResponsiveCanvas]]
 *
 * Generic [[Renderer]] utilizing [[ResponsiveCanvas]] element.
 * Refer to their documentation for more details. CanvasRenderer
 * can have several layers and there're two basic usage patterns.
 * Use separate layers for video and scene and effectively render
 * scene on top of the video stream. Advantage of this approach
 * is that image and scene can be processed independently and one
 * can apply different effects or postprocessing. This pattern is
 * also easier to implement. Or one can use only one canvas layer
 * and embed video stream into the scene as object via a texture
 * or background component. This approach will have more complex
 * implementation dependent on particular renderer. On the other
 * hand, rendering effects affecting the whole scene will also
 * apply to the video stream. This can improve performance and
 * allows advanced rendering/postprocessing techniques to be used
 *
 * @typeParam ResultT - Type of processing results
 */
declare class CanvasRenderer<ResultT extends {} = {}> extends Renderer<ResultT> {
    /** Responsive canvas */
    canvas: ResponsiveCanvas;
    /**
     * Constructor
     *
     * @param params - Parameters of responsive canvas
     */
    constructor(params: CanvasParams);
    /**
     * Set video parameters
     *
     * Callback passes aspect ratio to responsive canvas.
     *
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @override
     */
    setupVideo(size: Size, ratio?: number): void;
    /**
     * Set mirror mode
     *
     * CanvasRenderer sets mirror mode of ResponsiveCanvas.
     *
     * @param ratio - Mirror the output
     */
    setMirror(mirror: boolean): void;
}

/**
 * Generic video renderer
 *
 * Video renderer is based on [[CanvasRenderer]] and uses
 * two canvas layers: one for video stream and another to
 * render 3D scene on top of it. This usage pattern is the
 * easiest to implement, but more limited as video is not
 * embedded into the scene and e.g. renderer's postprocess
 * effects or advanced techniques can't be applied to video.
 *
 * @template ResultT - Type of processing results
 */
declare class VideoRenderer<ResultT extends {} = {}> extends CanvasRenderer<ResultT> {
    /** Drawing context of video canvas layer */
    protected videoCtx: CanvasRenderingContext2D | null;
    /**
     * Constructor
     *
     * @param params - Parameters of responsive canvas
     */
    constructor(params: CanvasParams);
    /**
     * Update the scene
     *
     * Draws input video frame on corresponding canvas layer.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: ResultT, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Update the video
     *
     * Draws input video frame on corresponding canvas layer.
     *
     * @param stream - Captured video frame
     */
    protected updateVideo(stream: HTMLCanvasElement): void;
    /**
     * Set video parameters
     *
     * Callback sets up size of video canvas layer.
     *
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @override
     */
    setupVideo(size: Size, ratio?: number): void;
}

/**
 * Generic scene plugin
 *
 * ScenePlugins can be attached to SceneRenderer instances.
 * Usually they control a scene node and implement simple
 * tasks that can be separated from main rendering context.
 * For example, make a scene node follow (be attached to)
 * person's head, or make node an occluder, or create face
 * mesh node and set texture as mask. ScenePlugin is very
 * similar to Renderer and also should implement two basic
 * methods load() and update(). It's a levels of abstraction
 * allowing to single out ready-made helpers that can be
 * reused as atomic building blocks in bigger application.
 *
 * @template ResultT - Type of processing results
 * @template SceneT - Type of renderer's scene
 */
declare class ScenePlugin<ResultT extends {} = {}, SceneT = undefined> {
    /** Loaded state */
    loaded: boolean;
    protected scene?: SceneT;
    /**
     * Initialize plugin
     *
     * Prepares or modifies the attached node if required.
     * Reference to the scene object is cached and used by
     * plugin on update() and unload(). You need to reload
     * plugin if you want to change scene it's attached to.
     * Overridden by derived classes for particular task.
     *
     * @param scene - Scene this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @virtual
     */
    load(scene?: SceneT): Promise<void>;
    /**
     * Reset plugin
     *
     * Releases all resources/instances created in load().
     * Overridden by derived classes for particular task.
     *
     * @virtual
     */
    unload(): void;
    /**
     * Update the scene node
     *
     * Main method implementing the logic of the plugin.
     * Updates the node according to provided results.
     * Overridden by derived classes for particular task.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @virtual
     */
    update(result: ResultT, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Dispose render plugin
     *
     * @virtual
     */
    dispose(): void;
}

/**
 * Generic video plugin
 *
 * VideoPlugin can be attached to SceneRenderer instances.
 * Usually they perform simple image transformations on
 * video stream, e.g. smooth effects or gamma correction.
 * VideoPlugin interface is very similar to Renderer and
 * consist of two basic methods load() and update(). But
 * instead of a scene, update() works with input image
 * provided within canvas element. Plugin is a level of
 * abstraction to single out ready-made helpers that can
 * be reused as atomic building blocks of the application.
 *
 * @template ResultT - Type of processing results
 */
declare class VideoPlugin<ResultT extends {} = {}> {
    /** Loaded state */
    loaded: boolean;
    /**
     * Initialize plugin
     *
     * Initializes everything required for image processing.
     * Overridden by derived classes for particular filter.
     *
     * @returns Promise resolving when initialization is finished
     * @virtual
     */
    load(): Promise<void>;
    /**
     * Reset plugin
     *
     * Releases all resources and instances created in load().
     * Overridden by derived classes for particular filter.
     *
     * @virtual
     */
    unload(): void;
    /**
     * Update the image
     *
     * Main method implementing image filter or 2D drawing.
     * Updates the image according to provided results.
     * Image is updated in place drawing on canvas directly.
     * Overridden by derived classes for particular filter.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @param canvas - Rendering context of canvas
     * @returns Promise resolving when update is finished
     * @virtual
     */
    update(result: ResultT, stream: HTMLCanvasElement, canvas: CanvasRenderingContext2D | null): Promise<void>;
    /**
     * Dispose render plugin
     *
     * @virtual
     */
    dispose(): void;
}

/**
 * Generic scene renderer
 *
 * Extends [[VideoRenderer]] to be used with particular webgl
 * engine e.g. babylon.js or three.js. Type of the scene is
 * additional parametrization of generic. The most important
 * feature of SceneRenderer is plugin system. Plugins written
 * for webgl engine can be attached to SceneRenderer. Usually
 * they perform simple rendering task that can be separated
 * from the context, for example add object on the scene that
 * follows (attached to) person's head or implement face mask.
 * [[ScenePlugin]] is not very different to SceneRenderer and
 * very much alike, but implements only one rendering task.
 * Plugins are levels of abstraction allowing to single out
 * ready-made helpers that are used as atomic building blocks.
 * Another type of plugins is [[VideoPlugin]] doing the same
 * but with input video frames, e.g. applying smooth filter.
 *
 * @template ResultT - Type of processing results
 * @template SceneT - Type of renderer's scene
 */
declare class SceneRenderer<ResultT extends {} = {}, SceneT = undefined> extends VideoRenderer<ResultT> {
    /** Renderer scene */
    protected scene?: SceneT;
    /** Attached plugins */
    protected plugins: (ScenePlugin<ResultT, SceneT> | VideoPlugin<ResultT>)[];
    /**
     * Constructor
     *
     * @param params - Parameters of responsive canvas
     */
    constructor(params: CanvasParams);
    /**
     * Initialize renderer
     *
     * Initializes all attached plugins.
     *
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(): Promise<void>;
    /**
     * Reset renderer
     *
     * Resets all attached plugins.
     *
     * @override
     */
    unload(): void;
    /**
     * Update the scene
     *
     * Calls updated of all attached plugins.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: ResultT, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Update and render the scene
     *
     * Virtual method updating and rendering the 3D scene.
     * Overridden by implementation for underlying renderer.
     *
     * @virtual
     */
    protected updateScene(): void;
    /**
     * Dispose renderer object
     *
     * Extended to dispose all attached plugins.
     *
     * @override
     */
    dispose(): void;
    /**
     * Add render plugin
     *
     * Initializes the plugin if it's not loaded yet but renderer is ready.
     * Renderer takes ownership of the plugin instance meaning it will
     * release it when plugin is detached or renderer is disposed itself.
     */
    addPlugin(plugin: ScenePlugin<ResultT, SceneT> | VideoPlugin<ResultT>): Promise<void>;
    /**
     * Remove render plugin
     *
     * Renderer will dispose the plugin before detaching it.
     */
    removePlugin(plugin: ScenePlugin<ResultT, SceneT> | VideoPlugin<ResultT>): void;
}

/**
 * Snapshot helper
 *
 * Takes snapshot of [[ResponsiveCanvas]] of [[CanvasRenderer]].
 * ResponsiveCanvas is multilayer so two modes are available:
 * capture all layers separately or merge them into one image.
 * When you call snapshot() method Snapshoter waits for the
 * next render update and makes a copy of all canvas layers.
 * There're several modes for the resolution of the snapshot:
 * "video" - snapshot has the same size as the video stream,
 * "max"/"min" - in maximum/minimum size among canvas layers.
 */
declare class Snapshoter {
    protected renderer: CanvasRenderer;
    protected mirror: boolean;
    protected sizeMode: "video" | "max" | "min";
    protected sizeMax?: number | undefined;
    /**
     * Constructor
     *
     * @param renderer - Renderer to take snapshot of
     * @param mirror - Mirror captured images
     * @param sizeMode - Video size mode
     * @param sizeMax - Maximum video size
     */
    constructor(renderer: CanvasRenderer, mirror?: boolean, sizeMode?: "video" | "max" | "min", sizeMax?: number | undefined);
    /**
     * Take snapshot of the renderer
     *
     * Enqueues capture after the next renderer update.
     * All canvas layers are merged into one final image.
     *
     * @returns Promise resolved to the merged captured image
     */
    snapshot(): Promise<ImageData | undefined>;
    /**
     * Take snapshot of the renderer
     *
     * Enqueues capture after the next renderer update.
     * All canvas layers are returned as separate images.
     *
     * @returns Promise resolved to the array of captured images
     */
    snapshotLayers(): Promise<(ImageData | undefined)[]>;
}

/**
 * Recorder helper
 *
 * Records video of [[ResponsiveCanvas]] of [[CanvasRenderer]].
 * ResponsiveCanvas is multilayer, every render update Recorder
 * merges all snapshots onto recording canvas. MediaRecorder is
 * records canvas content. Encoded video chunks are cached to
 * later be merged into one blob containing the final video file.
 * There're several modes for resolution of the recorded video:
 * "video" - records in the same resolution as the video stream,
 * "max"/"min" - in maximum/minimum size among layers of canvas.
 * Additionally one can limit resolution and bitrate of a video.
 */
declare class Recorder {
    protected renderer: CanvasRenderer;
    protected type: string;
    protected mirror: boolean;
    protected sizeMode: "video" | "max" | "min";
    protected sizeMax?: number | undefined;
    protected bitRate?: number | undefined;
    /** Canvas to capture video */
    protected canvas: HTMLCanvasElement;
    /** Drawing context of capturing canvas */
    protected context: CanvasRenderingContext2D | null;
    /** Video stream */
    protected stream?: MediaStream;
    /** Video recorder */
    protected recorder?: MediaRecorder;
    /** Record chunks */
    protected records: Blob[];
    /**
     * Constructor
     *
     * @param renderer - Renderer to record video from
     * @param type - Media/video type
     * @param mirror - Mirror captured images
     * @param sizeMode - Video size mode
     * @param sizeMax - Maximum video size
     * @param bitRate - Video stream bit rate
     */
    constructor(renderer: CanvasRenderer, type?: string, mirror?: boolean, sizeMode?: "video" | "max" | "min", sizeMax?: number | undefined, bitRate?: number | undefined);
    /**
     * Start video recording
     *
     * On every render update Recorder draws all layers onto
     * recording canvas. Chunks of encoded media stream are
     * cached to later be merged into one blob on stop().
     *
     * @returns True if recording started, False otherwise
     */
    start(): boolean;
    /**
     * Stop video recording
     *
     * Renderer stops recording and then merges encoded
     * video stream chunks into one blob returned to user.
     *
     * @returns Promise resolved to Blob containing encoded video
     */
    stop(): Promise<Blob | undefined>;
    /**
     * Dispose recorder object
     *
     * Releases resources and instances allocated by recorder.
     * Recorder object cannot be used after calling dispose().
     * One needs to stop recording before disposing the object.
     */
    dispose(): void;
    /**
     * Renderer update callback
     *
     * On every update Recorder draws all layers onto recording
     * canvas and requests video track to capture a new frame.
     */
    protected frame: () => void;
}

/**
 * Streamer helper
 *
 * Streams video of [[ResponsiveCanvas]] of [[CanvasRenderer]].
 * ResponsiveCanvas is multilayer, every render update Recorder
 * merges all snapshots onto one canvas. MediaStream instance is
 * created from canvas and provides access generated video stream
 */
declare class Streamer {
    protected renderer: CanvasRenderer;
    protected mirror: boolean;
    /** Canvas to capture video */
    protected canvas: HTMLCanvasElement;
    /** Drawing context of capturing canvas */
    protected context: CanvasRenderingContext2D | null;
    /** Output video stream */
    protected stream?: MediaStream;
    /**
     * Constructor
     *
     * @param renderer - Renderer to record video from
     * @param mirror - Mirror captured images
     */
    constructor(renderer: CanvasRenderer, mirror?: boolean);
    /**
     * Start video streaming
     *
     * On every Renderer update Streamer draws all layers onto
     * recording canvas. The canvas is a source of video stream.
     *
     * @returns True if recording started, False otherwise
     */
    start(): boolean;
    /**
     * Pause video streaming
     *
     * Stops drawing Renderer layers onto recording canvas.
     */
    pause(): void;
    /**
     * Media stream of generated video
     *
     * @returns Media stream
     */
    mediaStream(): MediaStream | undefined;
    /**
     * Render
     *
     * Every Renderer update Streamer merges snapshots of
     * multilayer ResponsiveCanvas onto recording canvas.
     */
    protected render: () => void;
}

export { AsyncEngine, CanvasParams, CanvasRenderer, Engine, EngineParams, EventEmitterT, ImageBuffer, ImageBytes, ImageInput, ProcParams, Processor, Recorder, Renderer, ResponsiveCanvas, ScenePlugin, SceneRenderer, Size, Snapshoter, Streamer, VideoCapture, VideoParams, VideoPlugin, VideoRenderer, VideoSource, VideoSourceParams };
